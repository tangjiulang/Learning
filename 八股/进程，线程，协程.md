# 进程

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个**运行中的程序，就被称为「进程」（Process）**

**多个程序、交替执行**的思想，就有 CPU 管理多个进程的初步想法。

对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。

虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生**并行的错觉**，实际上这是**并发**。

#### 并行和并发

![并发与并行](./../img/5-%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C.jpg)

CPU 从一个进程转移到另一个进程的时候，需要记录当前进程的所有状态信息，以便切换回来的时候恢复执行

## 进程的状态

**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](./../img/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

上图中各个状态的意义：

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](./../img/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

再来详细说明一下进程的状态变迁：

- *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
- *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
- *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
- *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
- *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
- *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
- *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

<img src="./../img/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg" alt="七种状态变迁" style="zoom:67%;" />

## 进程的控制结构

**进程控制块**（*process control block，PCB*）数据结构来描述进程

**PCB 是进程存在的唯一标识**

#### PCB 包括

**进程描述信息：**

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

- 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
- 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

- 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

PCB 一般通过链表的方式将所有相同状态的进程组成各种队列：

* 所有就绪状态的进程，就绪队列
* 所有阻塞的进程，阻塞队列

### 进程的控制

#### 创建进程

- 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
- 为该进程分配运行时所必需的资源，比如内存资源；
- 将 PCB 插入到就绪队列，等待被调度运行；

#### 终止进程

当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

- 查找需要终止的进程的 PCB；
- 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
- 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
- 将该进程所拥有的全部资源都归还给操作系统；
- 将其从 PCB 所在队列中删除；

#### 阻塞进程

- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
- 将该 PCB 插入到阻塞队列中去；

#### 唤醒进程

- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插入到就绪队列中，等待调度程序调度；

## 进程的上下文切换

**一个进程切换到另一个进程运行，称为进程的上下文切换**。进程是由内核管理和调度的，所以进程的切换只能发生在内核态。

所以，**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行

# 线程

**线程是进程当中的一条执行流程。**

同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。

**线程的优点**：

- 一个进程中可以同时存在多个线程；
- 各个线程之间可以并发执行；
- 各个线程之间可以共享地址空间和文件等资源；

**线程的缺点**：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃

## 进程和线程的区别

线程与进程的比较如下：

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；

对于，线程相比进程能减少开销，体现在：

- 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
- 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
- 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
- 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

所以，不管是时间效率，还是空间效率线程比进程都要高。

## 上下文切换

线程的上下文切换中，需要区分是否是统一进程。

不是同一进程，切换和进程一样

是同一进程，只需要切换寄存器，栈等私有资源。

## 线程实现

线程分为：

- **用户线程（*User Thread*）**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
- **内核线程（*Kernel Thread*）**：在内核中实现的线程，是由内核管理的线程；
- **轻量级进程（*LightWeight Process*）**：在内核中来支持用户线程；

### 用户线程

线程控制块 (TCB)

**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**

**优点**：

- 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；
- 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；

**缺点**：

- 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。
- 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。
- 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；

### 内核线程

**内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**

**优点**：

- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
- 分配给线程，多线程的进程获得更多的 CPU 运行时间；

**缺点**：

- 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；
- 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；

### 轻量级线程

**轻量级进程（\*Light-weight process，LWP\*）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度**。

在大多数系统中，**LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息**。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。

在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：

- `1 : 1`，即一个 LWP 对应 一个用户线程；
  - 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；
  - 缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。
- `N : 1`，即一个 LWP 对应多个用户线程；
  - 优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；
  - 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。
- `M : N`，即多个 LWP 对应多个用户线程；
  - 优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。

# 协程

协程（Coroutines）是一种比线程更加轻量级的存在。协程完全由程序所控制（在用户态执行）

 一个操作系统中可以有多个进程；一个进程可以有多个线程；同理，一个线程可以有多个协程。

协程是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处继续运行。

 **一个线程内的多个协程的运行是串行的，这点和多进程（多线程）在多核CPU上执行时是不同的。** 多进程（多线程）在多核CPU上是可以并行的。**当线程内的某一个协程运行时，其它协程必须挂起。**

### 协程切换

由于协程切换是在线程内完成的，涉及到的资源比较少。不像内核级线程（进程）切换那样，上下文的内容比较多，切换代价较大。协程本身是非常轻巧的，可以简单理解为只是切换了寄存器和协程栈的内容。这样代价就非常小。

#### 协程切换的问题

实际上协程只有在等待IO的过程中才能重复利用线程，也就是说协程本质是通过多路复用来完成的。但是有个问题是，协程本身不是线程，只是一个特殊的函数，它不能被操作系统感知到（操作系统只能感知到进程和内核级线程），如果某个线程中的协程调用了阻塞IO，那么将会导致线程切换发生。因此只有协程是不够的，是无法解决问题的。还需要异步来配合协程。

 **因此，实际上我们可以把协程可以看做是一种用户级线程的实现。**

# 调度

## 调度时机

当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度

根据如何处理时钟中断 ，把调度算法分为两类：

- **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
- **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

## 调度原则

**CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；

**系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；

**周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；

**等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；

**响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

## 调度算法

### 先来先服务调度算法

### 最短作业优先调度算法

### 高响应比优先调度算法

* $优先权=\frac{等待时间+服务时间}{服务时间}$

### 时间片轮转调度算法

* 每个线程分配一个时间片，时间片完了之后切换线程

### 最高优先级调度算法

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

### 多级反馈队列调度算法

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

#### 工作原理

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

# 进程间通信方式

## 管道

![img](./../img/5-%E7%AE%A1%E9%81%93-pipe.jpg)

**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。

父子进程之间的通信是由于 fork 的时候，子进程会复制父进程的文件描述符

管道是半双工通信，只能一端写入一端写出，所以我们在父子进程进行消息传递的时候，一般是关闭一个的写端和另一个的读端，如果要实现相互的消息传递，需要创建两个管道。

**对于匿名管道，它的通信范围是存在父子关系的进程**。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。

另外，**对于命名管道，它可以在不相关的进程间也能相互通信**。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。

不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。

## 消息队列

**消息队列是保存在内核中的消息链表**，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在

### 缺点

通信不及时

附件有大小限制

不适合大数据的传输

存在用户态和内核态的信息交换，有数据拷贝开销

## 共享内存

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

## 信号量

**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

## 信号

**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。

**1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。

**2.捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。

**3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。

## Socket

**跨网络与不同主机上的进程之间通信**

### 针对 TCP 协议通信的 socket 编程模型

![img](./../img/12-TCP%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

### 针对 UDP 协议通信的 socket 编程模型

![img](./../img/13-UDP%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg)

UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。

对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。

另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。

### 针对本地进程间通信的 socket 编程模型

- 本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；
- 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；

对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。

对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是**绑定一个本地文件**，这也就是它们之间的最大区别

# 线程冲突

- 同步：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；
- 互斥：「操作 A 和操作 B 不能在同一时刻执行」

## 互斥与同步的实现和使用

- *锁*：加锁、解锁操作；
- *信号量*：P、V 操作；

**原子操作**：**原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态**

### 忙等待锁(自旋锁)

当获取不到锁时，线程就会一直 while 循环，不做任何事情

```cpp
while(TestAndSet(&lock->flag, 1) == 1);
```

### 无等待锁

```cpp
while(TestAndSet(&lock->flag, 1) == 1) {
	// 保存当前线程的 TCB
	// 将当前线程插入到等待队列中
	// 设置状态为等待状态
	// 调度程序
}

if （lock->queue != NULL) {
	// 移除等待队列头部的线程
	// 插入到就绪队列中
	// 将线程设置为就绪状态
}
```

### 信号量

通常**信号量表示资源的数量**，对应的变量是一个整型（`sem`）变量。

另外，还有**两个原子操作的系统调用函数来控制信号量的**，分别是：

- *P 操作*：将 `sem` 减 `1`，相减后，如果 `sem < 0`，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
- *V 操作*：将 `sem` 加 `1`，相加后，如果 `sem <= 0`，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；

#### 互斥

我们的信号量为 1

1. 线程一访问临界资源，执行一次 P 操作，sem = 0，由于 sem < 0 条件不满足，线程继续执行
2. 线程二也访问临界资源，执行一次 P 操作， sem = -1，由于 sem < 0 线程二阻塞
3. 线程三也访问临界资源，执行一次 P 操作， sem = -2，由于 sem < 0 线程三阻塞
4. 线程一访问完毕，执行一次 V 操作，sem = -1，说明仍有线程因为此临界资源而处于等待阶段，唤醒一个线程，假设此时唤醒的是线程二
5. 线程二被唤醒，访问完毕，执行 V 操作，sem = 0，说明仍然有线程等待，此时唤醒线程三
6. 线程三被唤醒，访问完毕，执行 V 操作，sem = 1，说明没有线程等待。

PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。

#### 同步

设置信号量为 0

1. 线程一执行 P 操作， sem < 0，线程阻塞
2. 线程二执行 V 操作，sem = 0，唤醒线程一

保证了在线程二是在线程一之前。

#### 生产者消费者

```cpp
semaphore mutex = 1;
semaphore emptyBuffers = N;
semaphore fullBuffers = 0;

void producer() {
	while (TRUE) {
		P(empltyBuffers);
		P(mutex);
		do something
		V(mutex);
		V(fullBuffers);
	}
}

void cumstomer() {
	while (TRUE) {
		P(fullBuffers);
		P(mutex);
		do something
		V(mutex);
		V(emptyBuffers);
	}
}
```

## 哲学家问题

五个哲学家围成一个圈，每两个哲学家之间有一只筷子，只有拿到两只筷子，也就是一双筷子才能吃饭。

如果所有的哲学家都去拿左（右）边的筷子，那么大家都会处于阻塞等待状态，一直吃不上饭

下面有几个解决方案

### 方案一

既然会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量

```cpp
void smart_person(int i) {
	while (TRUE) {
		think();
		P(mutex);
		P(fork[i]);
		P(fork[(i + 1) % N]);
		eat();
		V(fork[(i + 1) % N]);
		V(fork[i]);
		V(mutex);
	}
}
```

但是这样同一个时间只有一个哲学家用餐，这样就会大大降低并发，使得系统变慢

### 方案二

**即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。**

```cpp
void smart_person(int i) {
	while (TRUE) {
		think();
		if (i % 2 == 0) {
			P[fork[i]];
			P[fork[(i + 1) % N]];
		} else {
			P[fork[(i + 1) % N]];
			P[fork[i]];
		}
		eat();
    V[fork[i]];
    V[fork[(i + 1) % N]];
	}
}
```

### 方案三

**用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。**

那么，**一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。**

```cpp
#define LEFT (i + N - 1) % N
#define RIGHT (i + 1) % N

#define THINKING 0 
#define HUNGRY 1
#define EATING 2

void test(int i) {
  	if (state[i] == HUNGRY && STATE[LEFT] != EATING && STATE[RIGHT] != EATING) {
      state[i] = EATING;
      V(s[i]);
    }
}

void take_forks(int i) {
  P(mutex);
  state[i] = HUNGRY;
  test(i);
  V(mutex);
  P(s[i]);
}

void put_forks(int i) {
  P(mutex);
  state[i] = THINKING;
  test(LEFT);
  test(RIGHT);
  V(mutex);
}

void smart_preson(int i) {
  while (TRUE) {
    think();
    take_forks(i);
    eat();
    put_forks(i);
  }
}
```

## 读者-写者问题

- 「读-读」允许：同一时刻，允许多个读者同时读
- 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
- 「写-写」互斥：没有其他写者时，写者才能写

### 方案一（读优先）

```cpp
void Writer() {
  while (TRUE) {
    P(wMutex);
    wirte();
    V(wMutex);
  }
}

void Reader() {
  while (TRUE) {
    P(rMutex);
    if (rCount == 0) {
      P(wMutex);
    }
    rCount++;
    V(rMutex);
    read();
    P(rMutex);
    rCount--;
    if (rCount == 0) {
      V(wMutex);
    }
    V(rMutex);
  }
}
```

### 方案二（写优先）

```cpp
void Writer() {
  while (TRUE) {
    P(wCountMutex);
    if (wCount == 0) {
      P(rMutex);
    }
    wCount++;
    V(wCountMutex);
    
    P(wDataMutex);
    write();
    V(wDataMutex);
    
    P(wCountMutex);
    wCount--;
    if (wCount == 0) {
      V(rMutex);
    }
    V(wCountMutex);
  }
}

void Reader() {
  while (TRUE) {
    P(rMutex);
    P(rCountMutex);
    if (rCount == 0) {
      P(wDataMutex);
    }
    rCount++;
    V(rCountMutex);
    V(rMutex);
    read();
    P(rMutex);
    P(rCountMutex);
    rCount--;
    if (rCount == 0) {
      V(wDataMutex);
    }
    V(rCountMutex);
    V(rMutex);
  }
}
```

注意，这里 `rMutex` 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 `P(rMutex)` 之后，后续的读者由于阻塞在 `rMutex` 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。

同时，第一个写者执行了 `P(rMutex)` 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 `V(wDataMutex)` 唤醒写者的写操作。

### 方案三（公平策略）

```cpp
void Writer() {
  while (TRUE) {
    P(flag);
    P(wDataMutex);
    Write();
    V(wDataMutex);
    V(flag);
  }
}

void Read() {
  while (TRUE) {
    P(flag);
    P(rCountMutex);
    if (rCount == 0) {
      P(wDataMutex);
    }
    rCount++;
    V(rCountMutex);
    V(flag);
    
    Read();
    
    P(rCountMutex);
    rCount--;
    if (rCount == 0) {
      V(wDataMutex);
    }
    V(rCountMutex);
  }
}
```

添加了一个 flag，flag 的作用是，当一些读操作进入读队列后，来了一个写操作，此时将临界资源 flag 占用了，后面的读操作就不能进入读队列了
